---
title: 'reward-protocol run'
description: 'Execute comprehensive evaluations with datasets and configurations'
---

# reward-protocol run

The `run` command is the primary tool for executing comprehensive evaluations using Eval Protocol. It leverages Hydra for configuration management, allowing you to define complex evaluation pipelines through YAML files.

## Basic Usage

```bash
reward-protocol run --config-name run_eval.yaml --config-path ./conf
```

## Command Syntax

```bash
reward-protocol run [OPTIONS] [OVERRIDES...]
```

### Options

#### --config-name, -cn
**Required.** Name of the configuration file (without .yaml extension).

```bash
reward-protocol run --config-name run_math_eval
```

#### --config-path, -cp
**Required.** Path to the directory containing configuration files.

```bash
reward-protocol run --config-path examples/math_example/conf
```

#### --overrides
Override configuration parameters from the command line.

```bash
reward-protocol run --config-name run_eval \
  generation.model_name="accounts/fireworks/models/llama-v3p1-405b-instruct" \
  evaluation_params.limit_samples=50
```

#### --help, -h
Show help message and available options.

```bash
reward-protocol run --help
```

## Configuration Structure

The run command expects YAML configuration files with specific sections:

### Basic Configuration Template

```yaml
# conf/run_eval.yaml
defaults:
  - dataset: my_dataset
  - generation: fireworks_generation
  - evaluation: my_evaluation
  - _self_

# Evaluation parameters
evaluation_params:
  limit_samples: null  # null for all samples
  output_name: "evaluation_results"
  save_preview_data: true

# Override specific settings
generation:
  enabled: true
  model_name: "accounts/fireworks/models/llama-v3p1-8b-instruct"

reward_functions:
  - name: "my_reward"
    module_path: "rewards.my_reward"
    function_name: "my_reward_function"
```

### Dataset Configuration

```yaml
# conf/dataset/my_dataset.yaml
defaults:
  - base_dataset
  - _self_

# Dataset source
dataset_name: "codeparrot/gsm8k"
dataset_config: "main"
split: "test"

# Preprocessing
system_prompt: "Solve the following math problem step by step."
output_format: "evaluation_format"
max_samples: 100

# Column mapping
column_mapping:
  input: "question"
  ground_truth: "answer"
```

### Generation Configuration

```yaml
# conf/generation/fireworks_generation.yaml
defaults:
  - base_generation
  - _self_

enabled: true
provider: "fireworks"
model_name: "accounts/fireworks/models/llama-v3p1-8b-instruct"

# Generation parameters
generation_params:
  max_tokens: 512
  temperature: 0.1
  top_p: 0.9
  stop_sequences: ["</answer>"]

# API configuration
api_config:
  timeout: 30
  max_retries: 3
  rate_limit: 10  # requests per second
```

### Evaluation Configuration

```yaml
# conf/evaluation/my_evaluation.yaml
defaults:
  - base_evaluation
  - _self_

# Reward functions to apply
reward_functions:
  - name: "math_accuracy"
    weight: 0.7
    module_path: "rewards.math"
    function_name: "math_accuracy_reward"
  
  - name: "reasoning_quality"
    weight: 0.3
    module_path: "rewards.reasoning"
    function_name: "reasoning_quality_reward"

# Evaluation settings
evaluation_params:
  parallel_workers: 4
  batch_size: 10
  fail_fast: false
```

## Examples

### Math Problem Evaluation

Evaluate model performance on GSM8K math problems:

```bash
# Basic evaluation
reward-protocol run \
  --config-name run_math_eval \
  --config-path examples/math_example/conf

# With custom parameters
reward-protocol run \
  --config-name run_math_eval \
  --config-path examples/math_example/conf \
  generation.model_name="accounts/fireworks/models/llama-v3p1-405b-instruct" \
  evaluation_params.limit_samples=20 \
  evaluation_params.output_name="math_eval_results"
```

### Code Generation Evaluation

Evaluate on APPS coding dataset:

```bash
reward-protocol run \
  --config-path examples/apps_coding_example/conf \
  --config-name run_eval \
  evaluation_params.limit_samples=5 \
  generation.generation_params.max_tokens=1024
```

### Custom Dataset Evaluation

```bash
reward-protocol run \
  --config-name custom_eval \
  --config-path ./my_configs \
  dataset.dataset_name="local_file" \
  dataset.file_path="./my_data.jsonl" \
  generation.model_name="gpt-4" \
  evaluation_params.output_name="custom_results"
```

### Evaluation-Only Mode

Skip generation and evaluate existing responses:

```bash
reward-protocol run \
  --config-name run_eval \
  --config-path ./conf \
  generation.enabled=false \
  evaluation_params.input_file="previous_results.jsonl"
```

### Parallel Processing

Run with multiple workers for faster processing:

```bash
reward-protocol run \
  --config-name run_eval \
  --config-path ./conf \
  evaluation_params.parallel_workers=8 \
  evaluation_params.batch_size=20
```

## Output Files

The run command generates several output files:

### Primary Results File

```
outputs/{timestamp}/{output_name}.jsonl
```

Contains detailed evaluation results:

```json
{
  "id": "sample_001",
  "messages": [...],
  "ground_truth": "42",
  "generation_metadata": {...},
  "evaluation_results": {
    "overall_score": 0.85,
    "reward_functions": {
      "math_accuracy": {
        "score": 0.9,
        "reason": "Correct answer",
        "metrics": {...}
      }
    }
  }
}
```

### Preview Data File

```
outputs/{timestamp}/preview_input_output_pairs.jsonl
```

Formatted for use with `reward-protocol preview`:

```json
{
  "messages": [...],
  "ground_truth": "42"
}
```

### Summary Report

```
outputs/{timestamp}/evaluation_summary.json
```

Overall statistics and metrics:

```json
{
  "total_samples": 100,
  "successful_evaluations": 98,
  "failed_evaluations": 2,
  "average_scores": {
    "overall": 0.76,
    "math_accuracy": 0.82,
    "reasoning_quality": 0.71
  },
  "execution_time": 245.6,
  "configuration": {...}
}
```

## Advanced Configuration

### Multi-Dataset Evaluation

```yaml
# conf/multi_dataset_eval.yaml
datasets:
  - name: "gsm8k"
    config: "conf/dataset/gsm8k.yaml"
    weight: 0.6
  - name: "math_word_problems"
    config: "conf/dataset/math_problems.yaml"
    weight: 0.4

evaluation_params:
  aggregate_results: true
  per_dataset_metrics: true
```

### A/B Testing Configuration

```yaml
# conf/ab_test_eval.yaml
model_variants:
  - name: "model_a"
    model_name: "accounts/fireworks/models/llama-v3p1-8b-instruct"
    temperature: 0.1
  - name: "model_b"
    model_name: "accounts/fireworks/models/llama-v3p1-70b-instruct"
    temperature: 0.1

evaluation_params:
  compare_variants: true
  statistical_significance: true
```

### Custom Preprocessing

```yaml
# conf/preprocessing/custom.yaml
preprocessing_steps:
  - name: "format_questions"
    function: "preprocessing.format_math_questions"
  - name: "add_context"
    function: "preprocessing.add_mathematical_context"
    params:
      context_type: "definitions"

dataset:
  preprocessing: "custom"
```

## Error Handling

### Common Issues and Solutions

#### Configuration File Not Found

```bash
Error: Configuration file not found at conf/missing_config.yaml
```

**Solution:** Verify the config path and filename:
```bash
ls -la conf/  # Check available configs
reward-protocol run --config-name existing_config --config-path conf/
```

#### Missing Dataset

```bash
Error: Dataset 'nonexistent/dataset' not found
```

**Solution:** Check dataset availability or use local file:
```yaml
dataset:
  dataset_name: "local_file"
  file_path: "./my_dataset.jsonl"
```

#### API Key Issues

```bash
Error: Authentication failed for Fireworks API
```

**Solution:** Set environment variables:
```bash
export FIREWORKS_API_KEY="your_key_here"
export FIREWORKS_ACCOUNT_ID="your_account_id"
reward-protocol run --config-name run_eval --config-path conf/
```

#### Memory Issues

```bash
Error: Out of memory processing large dataset
```

**Solution:** Reduce batch size and enable streaming:
```yaml
evaluation_params:
  batch_size: 5
  stream_processing: true
  limit_samples: 100
```

## Performance Optimization

### Parallel Processing

```yaml
evaluation_params:
  parallel_workers: 8      # Adjust based on CPU cores
  batch_size: 20          # Balance memory vs throughput
  prefetch_batches: 2     # Prepare batches ahead of time
```

### Memory Management

```yaml
evaluation_params:
  stream_processing: true     # Don't load entire dataset
  checkpoint_interval: 50    # Save progress every N samples
  cleanup_intermediate: true # Remove temp files
```

### API Rate Limiting

```yaml
generation:
  api_config:
    rate_limit: 10          # Requests per second
    burst_limit: 20         # Max burst requests
    timeout: 30             # Request timeout
    max_retries: 3          # Retry failed requests
```

## Integration with Other Commands

### Chain with Preview

```bash
# Run evaluation
reward-protocol run --config-name run_eval --config-path conf/

# Preview results
reward-protocol preview \
  --samples outputs/2024-01-15_14-30-45/preview_input_output_pairs.jsonl \
  --metrics-folders "math=./rewards/math"
```

### Chain with Deploy

```bash
# Test locally first
reward-protocol run --config-name test_eval --config-path conf/ \
  evaluation_params.limit_samples=5

# Deploy if tests pass
reward-protocol deploy \
  --id production-math-evaluator \
  --metrics-folders "math=./rewards/math" \
  --force
```

## Best Practices

1. **Start Small**: Test with `limit_samples` before full runs
2. **Use Version Control**: Keep configuration files in git
3. **Monitor Resources**: Watch CPU, memory, and API usage
4. **Checkpoint Progress**: Enable checkpointing for long runs
5. **Validate Configs**: Test configurations before production runs
6. **Document Changes**: Comment configuration modifications
7. **Backup Results**: Save important evaluation outputs

## Next Steps

- Learn about [Preview](/cli-reference/preview) for quick testing
- Explore [Deploy](/cli-reference/deploy) for production deployment
- Check [Examples](/examples/overview) for complete configurations
---
title: 'reward-protocol deploy'
description: 'Deploy evaluation functions to production environments'
---

# reward-protocol deploy

The `deploy` command packages and deploys your evaluation functions to production environments, making them available for use in training pipelines, evaluation systems, and other applications.

## Basic Usage

```bash
reward-protocol deploy --id my-evaluator --metrics-folders "metric=./path/to/metric" --force
```

## Command Syntax

```bash
reward-protocol deploy [OPTIONS]
```

### Required Options

#### --id
Unique identifier for the deployed evaluator.

```bash
reward-protocol deploy --id math-accuracy-evaluator
```

#### --metrics-folders
Specify evaluation functions to deploy using the format `name=path`.

```bash
# Single metric
reward-protocol deploy --id my-eval --metrics-folders "accuracy=./metrics/accuracy"

# Multiple metrics
reward-protocol deploy --id comprehensive-eval \
  --metrics-folders "accuracy=./metrics/accuracy" "clarity=./metrics/clarity"
```

### Optional Parameters

#### --force
Update the evaluator if it already exists (default: false).

```bash
reward-protocol deploy --id existing-evaluator --metrics-folders "metric=./path" --force
```

#### --target
Deployment target platform (default: "fireworks").

```bash
# Deploy to Fireworks AI
reward-protocol deploy --target fireworks --id my-eval --metrics-folders "metric=./path"

# Deploy as local server
reward-protocol deploy --target local-serve --id local-eval --metrics-folders "metric=./path"
```

#### --display-name
Human-readable name for the evaluator.

```bash
reward-protocol deploy \
  --id math-eval-v2 \
  --display-name "Math Problem Evaluator v2.0" \
  --metrics-folders "math=./rewards/math"
```

#### --description
Detailed description of the evaluator's purpose.

```bash
reward-protocol deploy \
  --id code-quality-eval \
  --description "Evaluates code quality, syntax, and best practices" \
  --metrics-folders "code=./rewards/code_quality"
```

#### --function-ref
Direct reference to a specific function (alternative to metrics-folders).

```bash
reward-protocol deploy \
  --id simple-eval \
  --function-ref "rewards.simple.basic_evaluation_function"
```

#### --verbose, -v
Show detailed deployment progress and debugging information.

```bash
reward-protocol deploy --id my-eval --metrics-folders "metric=./path" --verbose
```

#### --timeout
Set deployment timeout in seconds (default: 300).

```bash
reward-protocol deploy \
  --id large-eval \
  --metrics-folders "complex=./complex_metric" \
  --timeout 600
```

## Deployment Targets

### Fireworks AI (Default)

Deploy to Fireworks AI platform for scalable evaluation:

```bash
reward-protocol deploy \
  --target fireworks \
  --id production-math-eval \
  --display-name "Production Math Evaluator" \
  --description "Evaluates mathematical reasoning and accuracy" \
  --metrics-folders "math_accuracy=./rewards/math" \
  --force
```

**Requirements:**
- Fireworks API key: `FIREWORKS_API_KEY`
- Account ID: `FIREWORKS_ACCOUNT_ID`

**Features:**
- Automatic scaling
- High availability
- Built-in monitoring
- API endpoint generation

### Local Server

Deploy as a local HTTP server with external tunnel:

```bash
reward-protocol deploy \
  --target local-serve \
  --id local-dev-eval \
  --metrics-folders "dev_metric=./metrics/development" \
  --verbose
```

**Features:**
- Local development and testing
- External tunnel (ngrok/serveo)
- Real-time debugging
- No cloud dependencies

**Output:**
```
Starting local server on port 8001...
Creating external tunnel...
Local URL: http://localhost:8001
Public URL: https://abc123.ngrok.io
Evaluator registered with Fireworks AI
Server running in background (PID: 12345)
```

### Google Cloud Run

Deploy to Google Cloud Run for serverless scaling:

```bash
reward-protocol deploy \
  --target gcp-cloud-run \
  --id scalable-eval \
  --metrics-folders "production=./rewards/prod" \
  --gcp-project my-project \
  --gcp-region us-central1
```

## Configuration Examples

### Simple Deployment

```bash
# Basic math evaluator
reward-protocol deploy \
  --id math-eval \
  --metrics-folders "math=./rewards/math_accuracy" \
  --display-name "Math Problem Evaluator" \
  --force
```

### Multi-Metric Deployment

```bash
# Comprehensive code evaluator
reward-protocol deploy \
  --id code-comprehensive-eval \
  --display-name "Comprehensive Code Evaluator" \
  --description "Evaluates code syntax, logic, efficiency, and style" \
  --metrics-folders \
    "syntax=./rewards/code_syntax" \
    "logic=./rewards/code_logic" \
    "efficiency=./rewards/code_efficiency" \
    "style=./rewards/code_style" \
  --force \
  --verbose
```

### Development Deployment

```bash
# Local development server
reward-protocol deploy \
  --target local-serve \
  --id dev-test-eval \
  --function-ref "development.test_rewards.debug_function" \
  --verbose
```

### Production Deployment with Custom Settings

```bash
# Production deployment with custom configuration
reward-protocol deploy \
  --id prod-conversation-eval \
  --display-name "Production Conversation Evaluator" \
  --description "Evaluates conversation quality, safety, and helpfulness" \
  --metrics-folders \
    "quality=./rewards/conversation_quality" \
    "safety=./rewards/safety_check" \
    "helpfulness=./rewards/helpfulness" \
  --timeout 600 \
  --force
```

## Provider Configuration

### Custom Model Providers

```bash
# Deploy with specific model configuration
reward-protocol deploy \
  --id custom-model-eval \
  --metrics-folders "metric=./rewards/custom" \
  --providers '[
    {
      "providerType": "anthropic",
      "modelId": "claude-3-sonnet-20240229"
    }
  ]' \
  --force
```

### Multiple Provider Support

```bash
# Support multiple model providers
reward-protocol deploy \
  --id multi-provider-eval \
  --metrics-folders "adaptable=./rewards/adaptable" \
  --providers '[
    {
      "providerType": "fireworks",
      "modelId": "accounts/fireworks/models/llama-v3p1-8b-instruct"
    },
    {
      "providerType": "openai", 
      "modelId": "gpt-4"
    }
  ]' \
  --force
```

## Authentication Setup

### Fireworks AI

```bash
# Set environment variables
export FIREWORKS_API_KEY="your_api_key_here"
export FIREWORKS_ACCOUNT_ID="your_account_id"

# Or use config file
mkdir -p ~/.fireworks
cat > ~/.fireworks/auth.ini << EOF
[fireworks]
api_key = your_api_key_here
account_id = your_account_id
EOF
```

### Google Cloud Platform

```bash
# Authenticate with GCP
gcloud auth login
gcloud config set project your-project-id

# Set service account (optional)
export GOOGLE_APPLICATION_CREDENTIALS="path/to/service-account.json"
```

## Deployment Output

### Successful Deployment

```
Deploying evaluator: production-math-eval
✓ Validating evaluation functions...
✓ Packaging metrics...
✓ Uploading to Fireworks AI...
✓ Creating evaluator...
✓ Testing deployment...

Deployment successful!

Evaluator ID: production-math-eval
Display Name: Production Math Evaluator
Status: Active
API Endpoint: https://api.fireworks.ai/v1/evaluators/production-math-eval
Created: 2024-01-15 14:30:45 UTC

Metrics included:
  - math_accuracy: ./rewards/math_accuracy

Usage example:
  curl -X POST https://api.fireworks.ai/v1/evaluators/production-math-eval/evaluate \
    -H "Authorization: Bearer $FIREWORKS_API_KEY" \
    -H "Content-Type: application/json" \
    -d '{"messages": [...]}'
```

### Local Server Deployment

```
Deploying local server: dev-eval
✓ Starting HTTP server on port 8001...
✓ Creating ngrok tunnel...
✓ Registering with Fireworks AI...

Local server active!

Local URL: http://localhost:8001
Public URL: https://abc123.ngrok.io
Process ID: 12345

Test locally:
  curl -X POST http://localhost:8001/evaluate \
    -H "Content-Type: application/json" \
    -d '{"messages": [{"role": "assistant", "content": "test"}]}'

Stop server:
  kill 12345
```

## Management Commands

### List Deployed Evaluators

```bash
# List all deployed evaluators
reward-protocol list-evaluators

# Filter by status
reward-protocol list-evaluators --status active
```

### Update Existing Evaluator

```bash
# Update with new metrics
reward-protocol deploy \
  --id existing-evaluator \
  --metrics-folders "updated_metric=./rewards/v2" \
  --force
```

### Delete Evaluator

```bash
# Remove deployed evaluator
reward-protocol delete-evaluator --id old-evaluator
```

### Check Deployment Status

```bash
# Check evaluator health
reward-protocol status --id production-eval

# Get deployment details
reward-protocol describe --id production-eval
```

## Error Handling

### Common Issues

#### Authentication Error

```bash
Error: Authentication failed for Fireworks API
```

**Solution:**
```bash
# Check environment variables
echo $FIREWORKS_API_KEY
echo $FIREWORKS_ACCOUNT_ID

# Re-authenticate
export FIREWORKS_API_KEY="your_key"
export FIREWORKS_ACCOUNT_ID="your_account"
```

#### Metric Not Found

```bash
Error: Evaluation function not found in ./nonexistent/path
```

**Solution:**
```bash
# Verify path exists
ls -la ./rewards/
# Use correct path
reward-protocol deploy --metrics-folders "metric=./correct/path"
```

#### Port Already in Use (Local Server)

```bash
Error: Port 8001 already in use
```

**Solution:**
```bash
# Find and kill existing process
lsof -i :8001
kill <PID>

# Or use different port
reward-protocol deploy --target local-serve --port 8002
```

#### Deployment Timeout

```bash
Error: Deployment timed out after 300 seconds
```

**Solution:**
```bash
# Increase timeout
reward-protocol deploy --timeout 600 --id large-eval
```

## Monitoring and Maintenance

### Health Checks

```bash
# Test deployed evaluator
curl -X POST https://api.fireworks.ai/v1/evaluators/your-eval/evaluate \
  -H "Authorization: Bearer $FIREWORKS_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "assistant", "content": "Test response"}
    ]
  }'
```

### Log Access

```bash
# View deployment logs
reward-protocol logs --id production-eval --tail 100

# Stream live logs
reward-protocol logs --id production-eval --follow
```

### Performance Monitoring

```bash
# Get usage statistics
reward-protocol stats --id production-eval --period 7d

# Performance metrics
reward-protocol metrics --id production-eval
```

## Best Practices

1. **Test Locally First**: Use `--target local-serve` for development
2. **Use Descriptive IDs**: Choose clear, unique evaluator identifiers
3. **Include Documentation**: Use `--description` for detailed explanations
4. **Version Control**: Include version numbers in evaluator IDs
5. **Monitor Performance**: Set up alerting for production deployments
6. **Backup Configurations**: Save deployment commands in scripts
7. **Regular Updates**: Keep evaluators updated with latest metrics
8. **Security**: Rotate API keys regularly

## Integration Patterns

### CI/CD Pipeline

```bash
#!/bin/bash
# deploy.sh - Automated deployment script

# Test locally first
reward-protocol preview \
  --samples validation_set.jsonl \
  --metrics-folders "prod=./rewards/production" \
  --limit 10

# Deploy if tests pass
if [ $? -eq 0 ]; then
  reward-protocol deploy \
    --id "production-eval-$(date +%Y%m%d)" \
    --metrics-folders "prod=./rewards/production" \
    --force
else
  echo "Validation failed, aborting deployment"
  exit 1
fi
```

### A/B Testing

```bash
# Deploy version A
reward-protocol deploy \
  --id eval-variant-a \
  --metrics-folders "variant_a=./rewards/v1" \
  --force

# Deploy version B  
reward-protocol deploy \
  --id eval-variant-b \
  --metrics-folders "variant_b=./rewards/v2" \
  --force
```

## Next Steps

- Learn about [Run](/cli-reference/run) for comprehensive testing
- Explore [Preview](/cli-reference/preview) for development workflow
- Check [Examples](/examples/overview) for deployment patterns
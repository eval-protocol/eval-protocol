---
title: Introduction to Eval Protocol (EP)
sidebarTitle: Introduction
---

import { Workflow } from "/snippets/workflow.jsx"

EP is an [open specification](/specification), [Python
SDK](https://github.com/eval-protocol/python-sdk), and [pytest
plugin](https://docs.pytest.org/en/stable/how-to/writing_plugins.html) built to
standardize how developers author evals for large language model (LLM)
applications. It ensures that writing evals, storing traces, and saving eval
results follow a consistent pattern, and can be reused across various tasks like
model selection, prompt/context engineering, CI/CD, and fine-tuning for
real-world use cases‚Äîfrom tricky markdown generation and data extraction tasks
to complex customer service agents.

<Workflow />

For example, here is a example of an evaluation function that evaluates
responses from a [Policy](/specification#policy) based on the number of bullet
points in the response.

```python
# IFEval simple example
```

For a more advanced example that includes MCP and user simulation, check out our
implementation of [ùúè¬≤-bench](#), a benchmark for evaluating conversational
agents in a dual control environment.


### Next Steps

 - [Specification](/specification)
 - [Why Eval Protocol?](/why)
 - [Principles](/principles)
 - [Single-turn Evals](/quickstart)

---
title: Quick Start for Integrators
description: Integrate Eval Protocol into your existing workflows
---

# Quick Start for Integrators

This guide will help you integrate Eval Protocol into your existing ML workflows and infrastructure.

## Prerequisites

- Existing ML/AI infrastructure
- Python 3.8 or higher
- Understanding of your current evaluation pipeline

## Installation

Install Eval Protocol with integration extras:

```bash
pip install reward-protocol[integrations]
```

## Integration Patterns

### 1. TRL (Transformer Reinforcement Learning)

```python
from eval_protocol import load_function
from trl import PPOTrainer

# Load your reward function
reward_fn = load_function("your_reward_function")

# Integrate with TRL
trainer = PPOTrainer(
    model=model,
    ref_model=ref_model,
    tokenizer=tokenizer,
    dataset=dataset,
    reward_fn=reward_fn,  # Use your reward function
)

# Train with reward function
trainer.train()
```

### 2. Braintrust Integration

```python
from eval_protocol import reward_function
import braintrust

@reward_function
def custom_evaluator(query: str, response: str) -> float:
    # Your evaluation logic
    return score

# Use in Braintrust eval
braintrust.eval(
    project_name="my-project",
    data=eval_data,
    task=model_task,
    scores=[custom_evaluator]
)
```

### 3. Custom Pipeline Integration

```python
from eval_protocol import RewardProtocol

class MyEvaluationPipeline:
    def __init__(self):
        self.protocol = RewardProtocol()
        self.reward_functions = self.protocol.load_functions([
            "math_accuracy",
            "code_quality",
            "factual_correctness"
        ])
    
    def evaluate_batch(self, queries, responses):
        results = []
        for query, response in zip(queries, responses):
            scores = {}
            for name, fn in self.reward_functions.items():
                scores[name] = fn(query, response)
            results.append(scores)
        return results
```

## API Integration

### REST API

Deploy reward functions as REST endpoints:

```bash
reward-protocol serve --function math_accuracy --port 8000
```

Use the API:

```python
import requests

response = requests.post("http://localhost:8000/evaluate", json={
    "query": "What is 2 + 2?",
    "response": "The answer is 4"
})
score = response.json()["score"]
```

### Batch Processing

```python
from eval_protocol import BatchProcessor

processor = BatchProcessor()
processor.add_function("math_accuracy")
processor.add_function("code_quality")

# Process large datasets
results = processor.process_file("large_dataset.jsonl")
```

## Configuration

Create a configuration file for your integration:

```yaml
# reward_config.yaml
functions:
  - name: math_accuracy
    source: fireworks
    config:
      threshold: 0.8
  - name: custom_evaluator
    source: local
    path: ./my_functions.py

deployment:
  target: kubernetes
  replicas: 3
  resources:
    cpu: "1"
    memory: "2Gi"
```

## Next Steps

- **Advanced Integration**: Learn about [deployment patterns](/development/getting-started)
- **Monitoring**: Set up [evaluation monitoring](/integrations/overview)
- **Scaling**: Explore [distributed evaluation](/development/getting-started)

## Need Help?

- **Integration Docs**: Check platform-specific guides in [Integrations](/integrations/overview)
- **Community**: Join our [Discord for integrators](/community/support)
- **Enterprise**: Contact us for [enterprise support](/community/feedback)